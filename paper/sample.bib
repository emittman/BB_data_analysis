@book{intervals,
  title={Statistical Intervals: A Guide for Practioners and Researchers},
  author={Meeker, W.Q. and Hahn, G.H. and Escobar, L.A.},
  series={Wiley Series in Probability and Statistics},
  year={2017},
  publisher={Wiley}
}


@article{sujata,
  Author = {Rajarshi, Sujata and Rajarshi, M. B.},
  Title = {Bathtub distributions: {A} review},
  Journal = {Communications in {S}tatistics: {T}heory and {M}ethods},
  Volume = {17},
  Year = {1988},
  Pages = {2597--2621},
  Keywords = {Failure rate, Mean residual life, Survival data, Mortality analysis}
}

@article{reiser,
  title={Bayesian inference for masked system lifetime data},
  author={Reiser, B and Guttman, Irwin and Lin, Dennis KJ and Guess, Frank M and Usher, John S},
  journal={Applied {S}tatistics},
  pages={79--90},
  Volume={44},
  year={1995},
  publisher={JSTOR}
}

@article{berger,
  title={Bayesian analysis for the poly-Weibull distribution},
  author={Berger, James O and Sun, Dongchu},
  journal={Journal of the {A}merican {S}tatistical {A}ssociation},
  volume={88},
  number={424},
  pages={1412--1418},
  year={1993},
  publisher={Taylor \& Francis Group}
}

%probability plotting
@article{green,
  title={The errors of sampling of the survivorship tables},
  author={Greenwood, Major},
  journal={Reports on public health and statistical subjects},
  volume={33},
  number={1},
  pages={26},
  year={1926},
  publisher={HMSO London}
}

%model selection
@misc{loo,
    title = {loo: {E}fficient leave-one-out cross-validation and {W}{A}{I}{C} for
      {B}ayesian models},
    author = {Aki Vehtari and Andrew Gelman and Jonah Gabry},
    year = {2016},
    note = {R package version 1.1.0},
    url = {https://CRAN.R-project.org/package=loo},
  }
  

@Article{vehtari,
author="Vehtari, Aki
and Gelman, Andrew
and Gabry, Jonah",
title="Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC",
journal="Statistics and Computing",
year="2017",
month="Sep",
day="01",
volume="27",
number="5",
pages="1413--1432",
abstract="Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.",
issn="1573-1375",
doi="10.1007/s11222-016-9696-4",
url="https://doi.org/10.1007/s11222-016-9696-4"
}



%model assessment
@article{gelman1996postpred,
  title={Posterior predictive assessment of model fitness via realized discrepancies},
  author={Gelman, Andrew and Meng, Xiao-Li and Stern, Hal},
  journal={Statistica {S}inica},
  volume={6},
  pages={733--760},
  year={1996},
  publisher={JSTOR}
}




@book{nelson,
  title={{A}pplied {L}ife {D}ata {A}nalysis},
  author={Nelson, Wayne B},
  year={1982},
  publisher={John Wiley \& Sons}
}

@book{meeker,
  title={Statistical Methods for Reliability Data},
  author={Meeker, W.Q. and Escobar, L.A.},
  series={Wiley Series in Probability and Statistics},
  year={1998},
  publisher={Wiley}
}

@inproceedings{Schroeder,
 author = {Schroeder, Bianca and Gibson, Garth A.},
 title = {Disk {F}ailures in the {R}eal {W}orld: {W}hat {D}oes an {MTTF} of 1,000,000 {H}ours {M}ean to {Y}ou?},
 booktitle = {Proceedings of the 5th USENIX Conference on File and Storage Technologies},
 series = {FAST '07},
 year = {2007},
 location = {San Jose, CA},
 articleno = {1},
 publisher = {USENIX Association},
 address = {Berkeley, CA, USA},
} 


@article{harris,
  author  = {Harris, Robin}, 
  title   = {How Data Gets Lost},
  journal = {ZD Net Storage Bits},
  year    = 2007,
  month   = 8,
}

@article{smith,
  author = {Smith, David M.},
  title = {The Cost of Lost Data},
  journal = {Graziadio Business Review},
  volume = {6},
  number = {3},
  year = {2003},
} 

@article{turnbull,
  abstract = {This paper is concerned with the non-parametric estimation of a distribution function F, when the data are incomplete due to grouping, censoring and/or truncation. Using the idea of self-consistency, a simple algorithm is constructed and shown to converge monotonically to yield a maximum likelihood estimate of F. An application to hypothesis testing is indicated.},
  author = {Bruce W. Turnbull},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  number = {3},
  pages = {290-295},
  publisher = {[Royal Statistical Society, Wiley]},
  title = {The {E}mpirical {D}istribution {F}unction with {A}rbitrarily {G}rouped, {C}ensored and {T}runcated Data},
  volume = {38},
  year = {1976}
}

@article{kaplan,
  abstract = {In lifetesting, medical follow-up, and other fields the observation of the time of occurrence of the event of interest (called a death) may be prevented for some of the items of the sample by the previous occurrence of some other event (called a loss). Losses may be either accidental or controlled, the latter resulting from a decision to terminate certain observations. In either case it is usually assumed in this paper that the lifetime (age at death) is independent of the potential loss time; in practice this assumption deserves careful scrutiny. Despite the resulting incompleteness of the data, it is desired to estimate the proportion P(t) of items in the population whose lifetimes would exceed t (in the absence of such losses), without making any assumption about the form of the function P(t). The observation for each item of a suitable initial event, marking the beginning of its lifetime, is presupposed. For random samples of size N the product-limit (PL) estimate can be defined as follows: List and label the N observed lifetimes (whether to death or loss) in order of increasing magnitude, so that one has 0 ≤ t<sub>1</sub>' ≤ t<sub>2</sub>' ≤ ⋯ ≤ t<sub>N</sub>'. Then <tex-math>$\hat{P}(t) = \prod_r \lbrack(N - r)/(N - r + 1)\rbrack$</tex-math>, where r assumes those values for which t<sub>r</sub>' ≤ t and for which t<sub>r</sub>' measures the time to death. This estimate is the distribution, unrestricted as to form, which maximizes the likelihood of the observations. Other estimates that are discussed are the actuarial estimates (which are also products, but with the number of factors usually reduced by grouping); and reduced-sample (RS) estimates, which require that losses not be accidental, so that the limits of observation (potential loss times) are known even for those items whose deaths are observed. When no losses occur at ages less than t, the estimate of P(t) in all cases reduces to the usual binomial estimate, namely, the observed proportion of survivors.},
  author = {E. L. Kaplan, Paul Meier},
  journal = {Journal of the American Statistical Association},
  number = {282},
  pages = {457-481},
  publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
  title = {Nonparametric Estimation from Incomplete Observations},
  volume = {53},
  year = {1958}
}

@Misc{stan,
    title = {Stan: A C++ Library for Probability and Sampling, Version
      2.10.0},
    author = {{Stan Development Team}},
    year = {2015},
    url = {http://mc-stan.org/},
		}


@misc{backblaze,
author = {Backblaze},
title = {Backblaze hard drive data sets.},
year = {Accessed April 1, 2016}, 
howpublished = "\url{https://www.backblaze.com/b2/hard-drive-test-data.html}"}

@misc{backblaze2,
  title = {Backblaze hard drive data sets.},
  author = {Backblaze},
  url = {https://www.backblaze.com/b2/hard-drive-test-data.html},
  note = {Accessed: 2016-4-1}
}

@article{op,
 author = {J.E. Oppenlander, J. Schmee, G.J. Hahn},
 journal = {Commun. Statist.--Theor. Meth.},
 number = {17},
 pages = {2279-2301},
 title = {Some Simple Robust Estimators of Normal Distribution Tail Percentiles and Their Properties},
 volume = {7},
 year = {1988}
}

 @MISC{cpu,
   author =       "Lucas Mearian",
   title =        "Hard drive manufacturers slash warranty periods",
   editor =       "ComputerWorld.com",
   month =        "December",
   year =         "2011",
   url =          "\url{http://www.computerworld.com/article/2500542/data-center/hard-drive-manufacturers-slash-warranty-periods.html}",
   note =         "[Online; posted 16-December-2011]",
 }
 
 @book{gelman2014bayesian,
  title={{B}ayesian {D}ata {A}nalysis},
  author={Gelman, Andrew and Carlin, John B and Stern, Hal S and Rubin, Donald B},
  volume={2},
  year={2014},
  publisher={Chapman \& Hall/CRC Boca Raton, FL, USA}
}

@article{chan,
  title={A failure-time model for infant-mortality and wearout failure modes},
  author={Chan, Victor and Meeker, William Q},
  journal={IEEE Transactions on Reliability},
  volume={48},
  number={4},
  pages={377--387},
  year={1999},
  publisher={IEEE}
}

@article{basu,
  abstract = {Bayesian analysis of system failure data from engineering applications under a competing risks framework is considered when the cause of failure may not have been exactly identified but has only been narrowed down to a subset of all potential risks. In statistical literature, such data are termed masked failure data. In addition to masking, failure times could be right censored owing to the removal of prototypes at a prespecified time or could be interval censored in the case of periodically acquired readings. In this setting, a general Bayesian formulation is investigated that includes most commonly used parametric lifetime distributions and that is sufficiently flexible to handle complex forms of censoring. The methodology is illustrated in two engineering applications with a special focus on model comparison issues.},
  author = {Basu, Sanjib and Sen, Ananda and Banerjee, Mousimi},
  journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  number = {1},
  pages = {77-93},
  publisher = {[Wiley, Royal Statistical Society]},
  title = {Bayesian Analysis of Competing Risks with Partially Masked Cause of Failure},
  volume = {52},
  year = {2003}
}

@article{ranjan,
  title={A {B}ayes analysis of a competing risk model based on gamma and exponential failures},
  author={Ranjan, Rakesh and Singh, Sonam and Upadhyay, Satyanshu K},
  journal={Reliability Engineering \& System Safety},
  volume={144},
  pages={35--44},
  year={2015},
  publisher={Elsevier}
}

@article{hmm,
 ISSN = {19326157},
 URL = {http://www.jstor.org/stable/30244268},
 abstract = {Prediction of the remaining life of high-voltage power transformers is an important issue for energy companies because of the need for planning maintenance and capital expenditures. Lifetime data for such transformers are complicated because transformer lifetimes can extend over many decades and transformer designs and manufacturing practices have evolved. We were asked to develop statistically-based predictions for the lifetimes of an energy company's fleet of high-voltage transmission and distribution transformers. The company's data records begin in 1980, providing information on installation and failure dates of transformers. Although the dataset contains many units that were installed before 1980, there is no information about units that were installed and failed before 1980. Thus, the data are left truncated and right censored. We use a parametric lifetime model to describe the lifetime distribution of individual transformers. We develop a statistical procedure, based on age-adjusted life distributions, for computing a prediction interval for remaining life for individual transformers now in service. We then extend these ideas to provide predictions and prediction intervals for the cumulative number of failures, over a range of time, for the overall fleet of transformers.},
 author = {Yili Hong and William Q. Meeker and James D. McCalley},
 journal = {The Annals of Applied Statistics},
 number = {2},
 pages = {857-879},
 publisher = {Institute of Mathematical Statistics},
 title = {Prediction of Remaining Life of Power Transformers Based on Left Truncated and Right Censored Lifetime Data},
 volume = {3},
 year = {2009}
}

@article{xu2015assessing,
  title={Assessing risk of a serious failure mode based on limited field data},
  author={Xu, Zhibing and Hong, Yili and Meeker, William Q},
  journal={IEEE Transactions on Reliability},
  volume={64},
  number={1},
  pages={51--62},
  year={2015},
  publisher={IEEE}
}


@article{rstan,
  title={{R}stan: {R} {I}nterface to {S}tan},
  author={Guo, Jiqiang and Lee, D and Sakrejda, K and Gabry, J and Goodrich, B and De Guzman, J and Niebler, E and Heller, T and Fletcher, J},
  journal={R package version},
  volume={2},
  pages={0--3},
  year={2016}
}


@article{betancourt,
  title={Hamiltonian Monte Carlo for hierarchical models},
  author={Betancourt, Michael and Girolami, Mark},
  journal={Current trends in Bayesian methodology with applications},
  pages={79-101},
  year={2015},
  publisher={Chapman and Hall/CRC}
}

@article{r,
  title={{R}: {A} {L}anguage for {D}ata {A}nalysis and {G}raphics},
  author={Ihaka, Ross and Gentleman, Robert},
  journal={Journal of Computational and Graphical Statistics},
  volume={5},
  number={3},
  pages={299--314},
  year={1996},
  publisher={Taylor \& Francis}
}

@misc{f4562,
 title={Instructions for Form 4562},
 author={{U}{S} Department of {T}reasury, {IRS}},
 year={2016},
 howpublished ="\url{https://www.irs.gov/pub/irs-pdf/i4562.pdf}"}
}